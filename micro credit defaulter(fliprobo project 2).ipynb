{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing packages and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will import the libraries used for machine learning\n",
    "import numpy as np #linear algebra\n",
    "import pandas as pd #data processing , csv file\n",
    "from scipy.stats import randint\n",
    "import pandas as pd #data manipulation\n",
    "import matplotlib.pyplot as plt #used for plotting the graph\n",
    "import seaborn as sns #used for plot interactive graph\n",
    "from pandas import set_option\n",
    "plt.style.use('ggplot') #nice plots\n",
    "\n",
    "from sklearn.model_selection import train_test_split #to split data into two parts\n",
    "from sklearn.linear_model import LogisticRegression # to apply the LogisticRegression\n",
    "from sklearn.feature_selection import  RFE\n",
    "from sklearn.model_selection import KFold #foe cress validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV #search o hyper parameters\n",
    "from sklearn.preprocessing import StandardScaler #for normalization\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\" , category = FutureWarning)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/UCI_micro_Credit_defaulter.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"default.payment.next.month\": \"Default\"}, inplace=True)\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDUCATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDUCATION']=np.where(data['EDUCATION'] == 5,4, data['EDUCATION'])\n",
    "df['EDUCATION']=np.where(data['EDUCATION'] == 6,4, data['EDUCATION'])\n",
    "df['EDUCATION']=np.where(data['EDUCATION'] == 0,4, data['EDUCATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDUCATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MARRIAGE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MARRIAGE']=np.where(data['MARRIAGE'] == 0,3, data['MARRIAGE'])\n",
    "df['MARRIAGE'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the frequency of defaults\n",
    "yes = df.default.sum()\n",
    "no = len(df)-yes\n",
    "\n",
    "#percentage\n",
    "yes_perc = round(yes/len(df)*100, 1)\n",
    "no_perc = round(no/len(df)*100, 1)\n",
    "\n",
    "import sys\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "sns.countplot('Default', df=data, palette='Blues')\n",
    "plt.annotate('Non-Default': {}. format(no))\n",
    "plt.annotate('Non-Default': {}. format(yes))\n",
    "plt.title('COUNT OF MICRO CREDIT DEFAULTERS', size = 14)\n",
    "plt.box(false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option('display.width', 100)\n",
    "set_option('precision', 2)\n",
    "\n",
    "print(\"SUMMARY STATISTICS OF NUMERIC COLUMNS\")\n",
    "print()\n",
    "print(df.descibe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = list(data[data['Default'] == 1]['LIMIT_BAL'])\n",
    "x2 = list(data[data['Default'] == 0]['LIMIT_BAL'])\n",
    "\n",
    "plt.figure(figsize=(14,4))\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "#sns.set_color_codes(\"pastel\")\n",
    "plt.hist([x1, x2], bins = 40, normed=False, color=['steelblue', 'lightblue'])\n",
    "plt.xlim([0,60000])\n",
    "plt.legend(['Yes', 'No'], title = 'Default', loc='upper right', facecolor='white')\n",
    "plt.xlabel('Limit Balance (NT dollar)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('LIMIT BALANCE HISTOGRAM BY TYPE OF MICRO CREDIT DEFAULTER', SIZE=16)\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200, transparent=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repayment = df[['pay_0', 'pay_2', 'pay_3', 'pay_4', 'pay_5', 'pay_6']]\n",
    "Repayment = pd.contact([y,Repayment], axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "plt.xlim([-1.5,5.5])\n",
    "plt.box(False)\n",
    "plt.saveFig('Image Name', format='png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data are distributed in a wide range (below), need to be normalizded.\n",
    "plt.figure(figsize=(15,3))\n",
    "ax= data.drop('Default', axis=1).boxplot(data.columns.name, rot=90)\n",
    "outliers = dict(markerfacecolor='b', marker='p')\n",
    "ax= features.boxplot(features.columns.name, rot=90, flierprops=outliers)\n",
    "plt.xticks(size=12)\n",
    "ax.set_ylim([-5000,100000])\n",
    "plt.box(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at correlation matrix, defined via pearson function\n",
    "corr = df.corr()\n",
    "f, ax = plt.subplots(figsize=(8,7))\n",
    "sns.heatmap(corr, cbar = True, square = True, annot = False, fmt = '.1f', xticklabels = true,\n",
    "            yticklaels=True, cmap = \"coolwarm\", linewidth=5, ax=ax)\n",
    "plt.title('CORRELATION MATRIX = HEATMAP', size = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Dataset\n",
    "x = df.drop('Default', axis=1)\n",
    "y= df['Default']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, strafify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset with standardized features\n",
    "xstd_train, xstd_test, ystd_train, ystd_test = train_test_split(stdx, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 3\n",
    "model = LogisticRegression()\n",
    "rfe_stand = RFE(model, NUM_FEATURES)\n",
    "fit_stand = rfe_stand.fit(stdX, y)\n",
    "#print(\"St Model Num Features:\", fit_stand.n_features_)\n",
    "#print(\"St Model Selected Features:\", fit_stand.support_)\n",
    "print(\"Std Model Feature Ranking:\", fit_stand.ranking_)\n",
    "# calculate the score for the selected features\n",
    "score_stand = rfe_stand.score(stdX,y)\n",
    "print(\"Standardized Model Score with selected features is: %f (%f)\" % (score_stand.mean(), score_stand.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(features.columns)\n",
    "print('Most important features (RFE): %s' %feature_names[rfe_stand.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ximp = stdx[['PAY_0', 'BILL_AMT1', 'PAY_AMT2']]\n",
    "X_tr, X_t, y_tr, y_t = train_test_split(ximp, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the hyperparameter grid, (not scaled data)\n",
    "param_grid = {'C': np.logspace(-5, 8, 15)}\n",
    "\n",
    "# Instantiate a logistic regression classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "logreg_cv = RandomizedSearchCV(logreg,param_grid , cv=5, random_state=0)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "confMatrix = confusion_matrix(y_test, LRS.predict(x_test))\n",
    "sns.heatmap(confMatrix, annot=True, cmap=\"Blues\", fmt=\"d\",\n",
    "           xticklabels = ['Non-default', 'default'],\n",
    "           yticklabels = ['Non-default', 'default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('predicted label')\n",
    "plt.tile(\"confusion matrix - Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RandomizedSearchCV object:\n",
    "logreg_cv_std = RandomizedSearchCV(logreg,param_grid , cv=5, random_state=0)\n",
    "\n",
    "# Fit it to the standardized data\n",
    "logreg_cv_std.fit(Xstd_train, ystd_train)\n",
    "\n",
    "# Print the tuned parameters \n",
    "print(\"Tuned Logistic Regression Parameters with standardized features: {}\".format(logreg_cv_std.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "confMatrix = confusion_matrix(y_test, LRS.predict(x_test))\n",
    "sns.heatmap(confMatrix, annot=True, cmap=\"Blues\", fmt=\"d\",\n",
    "           xticklabels = ['Non-default', 'default'],\n",
    "           yticklabels = ['Non-default', 'default'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('predicted label')\n",
    "plt.tile(\"confusion matrix - Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random grid\n",
    "param_dist = {'n_estimators' : [50, 100, 150, 200, 250],\n",
    "             \"max_features\": [1,2,3,4,5,6,7,8,9],\n",
    "             \"max_depth\" : [1,2,3,4,5,6,7,8,9],\n",
    "             \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rf = RandomForestClassifier\n",
    "\n",
    "rf_cv = RandomizedSearchCV(rf, param_distributions = param_dist, cv=5, random_state=0, n_jobs = -1)\n",
    "rf_cv.fit(X,y)\n",
    " \n",
    "print(\"Tuned random forest parameters : %s\" % (rf_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_RF = Ran.predict_proba(X_test)[::,1]\n",
    "fpr1, tpr1, _ = metrics.roc_curve(y_test,  y_pred_proba_RF)\n",
    "auc1 = metrics.roc_auc_score(y_test, y_pred_proba_RF)\n",
    "\n",
    "y_pred_proba_DT = Tree.predict_proba(X_test)[::,1]\n",
    "fpr2, tpr2, _ = metrics.roc_curve(y_test,  y_pred_proba_DT)\n",
    "auc2 = metrics.roc_auc_score(y_test, y_pred_proba_DT)\n",
    "\n",
    "y_pred_proba_LR = LR.predict_proba(X_test)[::,1]\n",
    "fpr3, tpr3, _ = metrics.roc_curve(y_test,  y_pred_proba_LR)\n",
    "auc3 = metrics.roc_auc_score(y_test, y_pred_proba_LR)\n",
    "\n",
    "y_pred_proba_LRS = LRS.predict_proba(Xstd_test)[::,1]\n",
    "fpr4, tpr4, _ = metrics.roc_curve(ystd_test,  y_pred_proba_LRS)\n",
    "auc4 = metrics.roc_auc_score(ystd_test, y_pred_proba_LRS)\n",
    "\n",
    "y_pred_proba_LRimp = LR_imp.predict_proba(X_t)[::,1]\n",
    "fpr5, tpr5, _ = metrics.roc_curve(y_t,  y_pred_proba_LRimp)\n",
    "auc5 = metrics.roc_auc_score(y_t, y_pred_proba_LRimp)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr1,tpr1,label=\"Random Forest, auc=\"+str(round(auc1,2)))\n",
    "plt.plot(fpr2,tpr2,label=\"Decision Tree, auc=\"+str(round(auc2,2)))\n",
    "plt.plot(fpr3,tpr3,label=\"LogReg, auc=\"+str(round(auc3,2)))\n",
    "plt.plot(fpr4,tpr4,label=\"LogReg(std), auc=\"+str(round(auc4,2)))\n",
    "plt.plot(fpr5,tpr5,label=\"LogReg(Std&Imp), auc=\"+str(round(auc5,2)))\n",
    "plt.legend(loc=4, title='Models', facecolor='white')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC', size=15)\n",
    "plt.box(False)\n",
    "plt.savefig('ImageName', format='png', dpi=200, transparent=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate each model\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "# plot all the accuracy results vs each model\n",
    "fig = pyplot.figure(figsize=(10,5))\n",
    "sns.set_context('notebook', font_scale=1.1)\n",
    "fig.suptitle('Algorithm Comparison = Accuracy (cv=5)')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results, showmeans=True)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_ylim([0.75, 1])\n",
    "plt.box(False)\n",
    "plt.savefig('Image Name', format='png', dpi=200, transparent=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
